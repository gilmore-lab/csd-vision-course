<!DOCTYPE html>
<html>
<head>
  <title>Vision: How it works, how it develops, and why you should care</title>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'Vision: How it works, how it develops, and why you should care',
                        useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                      },

      // Author information
      presenters: [
            {
        name:  'Rick O. Gilmore' ,
        company: '',
        gplus: '',
        twitter: '',
        www: '',
        github: ''
      },
            ]
    };
  </script>

  <script src="libs/header-attrs-2.9/header-attrs.js"></script>
  <link href="libs/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="libs/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="libs/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="libs/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="libs/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="libs/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="libs/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="libs/ioslides-13.5.1/js/hammer.js"></script>
  <script src="libs/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="libs/ioslides-13.5.1/js/slide-deck.js"></script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    summary {
      display: list-item;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }
/* https://github.com/ropensci/plotly/pull/524#issuecomment-468142578 */
slide:not(.current) .plotly.html-widget{
  display: block;
}

    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
            
  </style>

  <link rel="stylesheet" href="css/ioslides.css" type="text/css" />

</head>

<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="title-slide segue nobackground">
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      
      <p data-config-presenter><!-- populated from slide_config.json --></p>
            <p style="margin-top: 6px; margin-left: -2px;">2021-08-30 09:00:11</p>
          </hgroup>
  </slide>

<!-- Scrolling final reference page -->

<!-- http://stackoverflow.com/q/38260799 -->

<style>
slides > slide { overflow: scroll; }
slides > slide:not(.nobackground):before {
  background: none;
  }
slides > slide:not(.nobackground):after {
  content: '';
  background: none;
  }
}
</style>

<slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>Preliminaries</h2></hgroup><article  id="preliminaries">

</article></slide><slide class=""><hgroup><h2>About me</h2></hgroup><article  id="about-me">

<ul>
<li>B.A., Cognitive Science, Brown University</li>
<li>M.S. &amp; Ph.D., Psychology (Cognitive Neuroscience), Carnegie Mellon University</li>
<li>Human brain development, perception &amp; action, computational modeling, machine vision, big data, open science</li>
<li>Founding Director of Human Imaging, Penn State Social, Life &amp; Engineering Sciences Imaging Center (SLEIC)</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<ul>
<li>Co-Founder/Co-Director of <a href='https://databrary.org' title=''>Databrary.org</a> data library</li>
<li><a href='https://gilmore-lab.github.io' title=''>gilmore-lab.github.io</a></li>
<li>banjo player, actor, cyclist, backpacker, poet, ham (K3ROG), native Coloradoan</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Agenda</h2></hgroup><article  id="agenda">

<ul>
<li>What’s vision for?</li>
<li>Properties of light</li>
<li>The visual eye and brain</li>
<li>Measuring the development of visual perception</li>
</ul>

</article></slide><slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>What’s vision for?</h2></hgroup><article  id="whats-vision-for">

</article></slide><slide class=""><hgroup><h2>Behavioral priorities</h2></hgroup><article  id="behavioral-priorities">

<ul>
<li>Secure sustenance</li>
<li>Avoid harm</li>
<li>Reproduce</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Behavioral primitives</h2></hgroup><article  id="behavioral-primitives">

<ul>
<li>Locomotion</li>
<li>Object interaction/manipulation</li>
<li>Communication</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Vision answers</h2></hgroup><article  id="vision-answers">

<ul>
<li>Where things are; where they’re moving; where/how I’m moving</li>
<li>What’s out there</li>
<li>How should I respond</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Vision informs observers about…</h2></hgroup><article  id="vision-informs-observers-about">

<ul>
<li>Geometry and motion of objects and surfaces</li>
<li>Surface properties (color, texture, rigidity)</li>
<li>Object properties (animate/inanimate; familiar/un-; person/animal…)</li>
</ul>

</article></slide><slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>Properties of light</h2></hgroup><article  id="properties-of-light">

</article></slide><slide class=""><hgroup><h2>Physics of sensation</h2></hgroup><article  id="physics-of-sensation">

<table class = 'rmdtable'>
<tr class="header">
<th align="left">Informal name</th>
<th align="left">Source</th>
</tr>
<tr class="odd">
<td align="left">Vision</td>
<td align="left">Electromagnetic radiation</td>
</tr>
<tr class="even">
<td align="left">Audition</td>
<td align="left">Mechanical vibration in air/water</td>
</tr>
<tr class="odd">
<td align="left">Touch</td>
<td align="left">Mechanical vibration of skin on surface</td>
</tr>
<tr class="even">
<td align="left">Vestibular</td>
<td align="left">Rotation &amp; linear acceleration of head</td>
</tr>
<tr class="odd">
<td align="left">Olfaction</td>
<td align="left">Chemical patterns in air/water</td>
</tr>
<tr class="even">
<td align="left">Gustation</td>
<td align="left">Chemical patterns in mouth</td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<table class = 'rmdtable'>
<tr class="header">
<th align="left">Informal name</th>
<th align="left">Source</th>
</tr>
<tr class="odd">
<td align="left">Electroception</td>
<td align="left">Electromagnetic radiation</td>
</tr>
<tr class="even">
<td align="left">Magnetoreception</td>
<td align="left">Electromagnetic radiation patterns</td>
</tr>
<tr class="odd">
<td align="left">Kinesthesia</td>
<td align="left">Position, velocity, acceleration of limbs, body</td>
</tr>
</table>

</article></slide><slide class=""><hgroup><h2>Plenoptic function</h2></hgroup><article  id="plenoptic-function">

<div class="figure" style="text-align: center">
<img src="img/plenoptic-function-adelson-1991.jpg" alt="[(Adelson &amp; Bergen, 1991)](http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.2.9848)" width="500px" />

<p class="caption">

<a href='http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.2.9848' title=''>(Adelson &amp; Bergen, 1991)</a>

</p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://media.springernature.com/original/springer-static/image/prt%3A978-0-387-31439-6%2F15/MediaObjects/978-0-387-31439-6_15_Part_Fig1-7_HTML.gif" alt="[[@Chan2014-il]](https://doi.org/10.1007/978-0-387-31439-6_7)"  />

<p class="caption">

<a href='https://doi.org/10.1007/978-0-387-31439-6_7' title=''><span class="cite">(Chan, 2014)</span></a>

</p></div>

</article></slide><slide class=""><hgroup><h2>Light</h2></hgroup><article  id="light">

<ul>
<li>Electromagnetic (EM) radiation</li>
<li>Wavelength (1/frequency) and intensity</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/EM_Spectrum_Properties_edit.svg/1200px-EM_Spectrum_Properties_edit.svg.png" alt="Source: Wikipedia" width="900px" />

<p class="caption">

Source: Wikipedia

</p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="centered">
<p>Reflects off surfaces to different degrees</p>

<p><img src="https://www.cns.nyu.edu/~david/courses/perception/lecturenotes/color/color-slides/Slide14.jpg"></p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="centered">
<p>Perceived color differences correspond to different patterns of light reflection.</p>

<p><img src="https://sites.google.com/site/obeluwa/_/rsrc/1372214890170/skin/introduction-to-diffuse-reflectance-spectroscopy/sample-spectra.png"></p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="centered">
<p>Light is refracted (bent) by some substances</p>

<p><img src="https://www.sciencelearn.org.nz/system/images/images/000/000/050/embed/Converging-lens20150805-30610-9sjoqh.jpg?1447040428"></p></div>

</article></slide><slide class=""><hgroup><h2>Light</h2></hgroup><article  id="light-1">

<ul>
<li>Provides fast (2.99 million m/s; 186 million mi/hr) information about surfaces at a distance</li>
<li>vs. sound (340 m/s; 767 mi/hr)</li>
<li>vs. chemical signals (min/mi)</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Projects images that relate to shape/orientation</h2></hgroup><article  id="projects-images-that-relate-to-shapeorientation">

<p><img src="https://thebrain.mcgill.ca/flash/a/a_02/a_02_p/a_02_p_vis/a_02_p_vis_1p.jpg" width="900px" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<p><img src="https://thebrain.mcgill.ca/flash/a/a_02/a_02_p/a_02_p_vis/a_02_p_vis_1q.jpg" width="900px" style="display: block; margin: auto;" /></p>

</article></slide><slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>The visual eye and brain</h2></hgroup><article  id="the-visual-eye-and-brain">

</article></slide><slide class=""><hgroup><h2>The eye</h2></hgroup><article  id="the-eye">

<p><img src="https://hmslade5.files.wordpress.com/2012/03/anatomy-of-the-eye.jpg" width="600px" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>as an auto-focus, auto-exposure camera…</h2></hgroup><article  id="as-an-auto-focus-auto-exposure-camera">

<p><img src="https://www.optilase.com/wp-content/uploads/2014/12/camera-lens-eye-lens.jpg" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>part of a self-stabilizing system…</h2></hgroup><article  id="part-of-a-self-stabilizing-system">

<!-- Kestrel showing image stabilization -->

<iframe width="560" height="315" src="https://www.youtube.com/embed/JGArTWOJtXs?start=7" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>

</iframe>

</article></slide><slide class=""><hgroup><h2>The retina…</h2></hgroup><article  id="the-retina">

<p><img src="https://www.feinberg.northwestern.edu/gfx/news/retina.jpg" width="600px" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>…samples light intensity, wavelength, and spatial pattern</h2></hgroup><article  id="samples-light-intensity-wavelength-and-spatial-pattern">

</article></slide><slide class=""><hgroup><h2>via &lsquo;wavelength-tuned&rsquo; photoreceptors</h2></hgroup><article  id="via-wavelength-tuned-photoreceptors">

<div class="centered">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/94/1416_Color_Sensitivity.jpg/1200px-1416_Color_Sensitivity.jpg" width="800px" style="display: block; margin: auto;" /></p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://i.pinimg.com/originals/9f/08/85/9f0885d4c209d5275f631ac194eb4f4b.jpg" alt="Peripheral retina" height="500px" />

<p class="caption">

Peripheral retina

</p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://upload.wikimedia.org/wikipedia/commons/a/a6/ConeMosaics.jpg" alt="Central retina" width="800px" />

<p class="caption">

Central retina

</p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Human_photoreceptor_distribution.svg/1200px-Human_photoreceptor_distribution.svg.png" alt="Source: Wikipedia" width="600px" />

<p class="caption">

Source: Wikipedia

</p></div>

</article></slide><slide class=""><hgroup><h2>Photoreceptor information processing</h2></hgroup><article  id="photoreceptor-information-processing">

<ul>
<li>Separate channels for short, medium, long wavelengths (cones): chromatic</li>
<li>Black/gray/white or overall illumination (rods): achromatic</li>
<li>Point by point, topographic image</li>
<li>Non-uniform resolution (center &gt;&gt; periphery)</li>
<li>Focused by cornea (passive) + lens (active), except…</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<!-- Myopia -->

<p><img src="https://ecpbuilder.com/wp-content/uploads/sites/530/2015/10/myopia.jpg" width="700px" style="display: block; margin: auto;" /></p>

</article></slide><slide class=""><hgroup><h2>The visual brain</h2></hgroup><article  id="the-visual-brain">

<div class="figure" style="text-align: center">
<img src="https://images.squarespace-cdn.com/content/v1/571fba899f7266a7171030cf/1462222122503-RFJMLWD4XWA4EJT4K0FO/image-asset.jpeg?format=1500w" alt="(Logothetis, N., November 1999. Vision: A window on consciousness. Scientific American" height="550px" />

<p class="caption">

(Logothetis, N., November 1999. Vision: A window on consciousness. Scientific American

</p></div>

</article></slide><slide class=""><hgroup><h2>Primary (feedforward) pathway</h2></hgroup><article  id="primary-feedforward-pathway">

<ul>
<li>Retina -&gt;</li>
<li>Thalamus -&gt;</li>
<li>Primary visual cortex (V1) in occipital lobe</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<!-- Visual projections to thalamus -->

<div class="centered">
<p><img src="https://i.stack.imgur.com/Go7pv.gif" height="600px" style="display: block; margin: auto;" /></p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<!-- Projection to visual cortex -->

<div class="centered">
<p><img src="https://cdn.theconversation.com/files/139134/width754/image-20160926-13523-17pujyt.png" width="800px" style="display: block; margin: auto;" /></p></div>

</article></slide><slide class=""><hgroup><h2>Retinotopic map</h2></hgroup><article  id="retinotopic-map">

<div class="figure" style="text-align: center">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Retinotopic_English.jpg/700px-Retinotopic_English.jpg" alt="https://en.wikipedia.org/wiki/Retinotopy"  />

<p class="caption">

<a href='https://en.wikipedia.org/wiki/Retinotopy' title=''>https://en.wikipedia.org/wiki/Retinotopy</a>

</p></div>

</article></slide><slide class=""><hgroup><h2>Visual processing dominates the primate brain</h2></hgroup><article  id="visual-processing-dominates-the-primate-brain">

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://www.jneurosci.org/content/jneuro/23/10/3981/F1.large.jpg" alt="[[@Tootell2003-oo]](https://www.ncbi.nlm.nih.gov/pubmed/12764082)" height="500px" />

<p class="caption">

<a href='https://www.ncbi.nlm.nih.gov/pubmed/12764082' title=''><span class="cite">(Tootell, Tsao, &amp; Vanduffel, 2003)</span></a>

</p></div>

</article></slide><slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>Measuring visual function and its development</h2></hgroup><article  id="measuring-visual-function-and-its-development">

</article></slide><slide class=""><hgroup><h2>Psychophysical functions</h2></hgroup><article  id="psychophysical-functions">

<div class="centered">
<p><img src="https://www.psywww.com/intropsych/ch04-senses/04stevenscurves.jpg" height="500px" style="display: block; margin: auto;" /></p></div>

</article></slide><slide class=""><hgroup><h2>Psychophysical methods</h2></hgroup><article  id="psychophysical-methods">

<ul>
<li><em>Method of constants</em> (fixed levels)</li>
<li><em>Method of adjustment</em> (raise/lower amplitude until detectable/indetectable)</li>
<li><em>Method of limits</em> (&ldquo;can you see me now? now?&rdquo;; often use staircases)</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Psychophys<em>iolog</em>ical functions</h2></hgroup><article  id="psychophysiological-functions">

<div class="figure" style="text-align: center">
<img src="https://media.springernature.com/full/springer-static/image/art%3A10.1203%2F01.pdr.0000238249.44088.2c/MediaObjects/41390_2006_Article_BFpr2006267_Fig1_HTML.jpg?as=webp" alt="[[@Mirabella2006-ro]](http://dx.doi.org/10.1203/01.pdr.0000238249.44088.2c)" width="700px" />

<p class="caption">

<a href='http://dx.doi.org/10.1203/01.pdr.0000238249.44088.2c' title=''><span class="cite">(Mirabella, Kjaer, Norcia, Good, &amp; Madan, 2006)</span></a>

</p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1203%2F01.pdr.0000238249.44088.2c/MediaObjects/41390_2006_Article_BFpr2006267_Fig2_HTML.jpg?as=webp" alt="[[@Mirabella2006-ro]](http://dx.doi.org/10.1203/01.pdr.0000238249.44088.2c)" width="600px" />

<p class="caption">

<a href='http://dx.doi.org/10.1203/01.pdr.0000238249.44088.2c' title=''><span class="cite">(Mirabella, Kjaer, Norcia, Good, &amp; Madan, 2006)</span></a>

</p></div>

</article></slide><slide class=""><hgroup><h2>Acuity (detail/pattern vision)</h2></hgroup><article  id="acuity-detailpattern-vision">

<ul>
<li>Grating acuity</li>
<li>Vernier</li>
<li>Symbol/letter (optotype) acuity</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Similar rates of development across primate species</h2></hgroup><article  id="similar-rates-of-development-across-primate-species">

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://www.jneurosci.org/content/jneuro/36/45/11384/F2.large.jpg" alt="[[@Kiorpes2016-ut]](http://dx.doi.org/10.1523/JNEUROSCI.2937-16.2016)" height="550px" />

<p class="caption">

<a href='http://dx.doi.org/10.1523/JNEUROSCI.2937-16.2016' title=''><span class="cite">(Kiorpes, 2016)</span></a>

</p></div>

</article></slide><slide class=""><hgroup><h2>Measuring visual acuity</h2></hgroup><article  id="measuring-visual-acuity">

<!-- Measuring visual acuity HOTV and Lea symbols -->

<div class="centered">
<p><img src="https://s3.amazonaws.com/cdn.bernell.com/images/uploads/712_4817_thumb.jpg" height="500px" style="display: block; margin: auto;" /></p></div>

</article></slide><slide class=""><hgroup><h2>Contrast sensitivity</h2></hgroup><article  id="contrast-sensitivity">

<ul>
<li>Light/dark ratio vs. spatial frequency (level of detail)</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://www.psychophysics.uk/wp-content/uploads/2019/04/typical-contrast-sensitivity-function.jpg" alt="Contrast sensitivity function"  />

<p class="caption">

Contrast sensitivity function

</p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://www.researchgate.net/publication/313816987/figure/fig2/AS:614249734864898@1523459957272/Pelli-Robson-contrast-sensitivity-chart-Precision-Vision-LaSalle-IL-11-The_Q640.jpg" alt="Pelli-Robson Contrast Sensitivity Chart" height="550px" />

<p class="caption">

Pelli-Robson Contrast Sensitivity Chart

</p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://arvo.silverchair-cdn.com/arvo/content_public/journal/jov/933685/m_i1534-7362-14-13-16-f01.png?Expires=1633350425&Signature=CMSwqDhlJZds54KXDfPyXQAuhDLaO-WsVKUkrA99glxv6j4QcgBaOxnkAsVEQ7W5s8hX9wdF9fw0I-dLXGDEZMYc7lYTTV~lV4AR4-MPfn1JiDRHRtfIo7Vcg~fbgIc3OU5IouEz33aBVXD1S5oZPeP3bmbAcx60sMk5nZdRKd7mA6~1OhDqiSxqIr0mudzpo2snp~04XPMvuMpRWJCUo6BMl6rOyqRyTKIBI26rZN~Wxg6ljkled6sxxIIawVBjCTbrfCQ6lGL9x07ZqbcpQD6ElOPGBlsLH3sGIPyZslu3cFK4ci0EHyyxmpUDe1AMBFrQYMhjvHJr~tkUbJdhDw__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="[[@Von_Hofsten2014-gy]](http://dx.doi.org/10.1167/14.13.16)"  />

<p class="caption">

<a href='http://dx.doi.org/10.1167/14.13.16' title=''><span class="cite">(Hofsten et al., 2014)</span></a>

</p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://arvo.silverchair-cdn.com/arvo/content_public/journal/jov/933685/m_i1534-7362-14-13-16-f04.png?Expires=1633350425&Signature=TisxSffCw-925oXEn9ZLATW28JICQZCOb-7B1fKopFLdDANlui0KvNELEv5-fiIrXa7-0LwM7~rybCHpXhPcY5F4XIunTdCS9GJLCqgSOfzpyTkfgJ9WnYeF8cqr0HQ5XmM7bVaTpozBScMk0~HXHxenK1pA189j-YAOkmwRQaJQqg5~SQ8KYz0xzRIfpNts-CXql3SnTC41eg4FMdAVVx4LYcE4GKkpFHFBFT~H~QgFf3pKtRWgpVPUWXEV99T3vRUph3Ls~5zHjNvHvzLYDN1ho2EdCnpwmhHY4XSbeaJk8JeSoP-ToTmcZ-o5VhNepehJ7FJKVrCghOE9R6inVg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="[[@Von_Hofsten2014-gy]](http://dx.doi.org/10.1167/14.13.16)" width="800px" />

<p class="caption">

<a href='http://dx.doi.org/10.1167/14.13.16' title=''><span class="cite">(Hofsten et al., 2014)</span></a>

</p></div>

</article></slide><slide class=""><hgroup><h2>Similar rates of development across primate species</h2></hgroup><article  id="similar-rates-of-development-across-primate-species-1">

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="centered">

<div class="figure" style="text-align: center">
<img src="https://www.jneurosci.org/content/jneuro/36/45/11384/F3.large.jpg" alt="[[@Kiorpes2016-ut]](http://dx.doi.org/10.1523/JNEUROSCI.2937-16.2016)" height="500px" />

<p class="caption">

<a href='http://dx.doi.org/10.1523/JNEUROSCI.2937-16.2016' title=''><span class="cite">(Kiorpes, 2016)</span></a>

</p></div>

</article></slide><slide class=""><hgroup><h2>Effects of poor contrast sensitivity on newborn vision</h2></hgroup><article  id="effects-of-poor-contrast-sensitivity-on-newborn-vision">

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="centered">

<div class="figure" style="text-align: center">
<img src="https://www.jneurosci.org/content/jneuro/36/45/11384/F4.large.jpg" alt="[[@Kiorpes2016-ut]](http://dx.doi.org/10.1523/JNEUROSCI.2937-16.2016)" width="900px" />

<p class="caption">

<a href='http://dx.doi.org/10.1523/JNEUROSCI.2937-16.2016' title=''><span class="cite">(Kiorpes, 2016)</span></a>

</p></div>

</article></slide><slide class=""><hgroup><h2>Motion coherence (Signal vs. noise)</h2></hgroup><article  id="motion-coherence-signal-vs.-noise">

<iframe width="560" height="315" src="https://www.youtube.com/embed/2DdlcdFeO9I" frameborder="0" allowfullscreen>

</iframe>

</article></slide><slide class=""><hgroup><h2>Rate of development varies across visual functions</h2></hgroup><article  id="rate-of-development-varies-across-visual-functions">

<ul>
<li>Some (e.g., motion sensitivity) not adult-like until early teens</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://www.jneurosci.org/content/jneuro/36/45/11384/F5.large.jpg" alt="[[@Kiorpes2016-ut]](http://dx.doi.org/10.1523/JNEUROSCI.2937-16.2016)"  />

<p class="caption">

<a href='http://dx.doi.org/10.1523/JNEUROSCI.2937-16.2016' title=''><span class="cite">(Kiorpes, 2016)</span></a>

</p></div>

</article></slide><slide class=""><hgroup><h2>Atypical development: Autism</h2></hgroup><article  id="atypical-development-autism">

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/brain/133/2/10.1093/brain/awp272/2/awp272f3.gif?Expires=1633351432&Signature=PDQgU2OJX5HOhegH07b-zYZjmnoZ8rIvmxzs6pbHB1i-O-xK6yyOmbLpepDBEKksNAoJAh04qt-zBkkdSXtQun5Ub0DlFKud5zb2znvMzbtEReNb8h48c~ZA3KYvvosntOsO9E~8sYqEJpKw6PN5YmYtcJ~YDMCPZv7VURCIn4J2KqSGJbg~kYfkM5JfTQ4KWTtoQWHYUnSG7zGAANOJhmyqA0TuAGRm9FQgaR7ek1jN9ZYerH2O99xf~u1KMWLUsed9r2c5d3UJJrmsEo4F6iBOCQDBHNRjNGLcMt5c8p~k479GEXu24cn5BCjZi-5LqXgWw04~U~nReXT6WIyoVw__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="[[@Koldewyn2010-ap]](https://dx.doi.org/10.1093/brain/awp272)" width="500px" />

<p class="caption">

<a href='https://dx.doi.org/10.1093/brain/awp272' title=''><span class="cite">(Koldewyn, Whitney, &amp; Rivera, 2010)</span></a>

</p></div>

</article></slide><slide class=""><hgroup><h2>Atypical development: Amblyopia</h2></hgroup><article  id="atypical-development-amblyopia">

<ul>
<li><strong>Amblyopia</strong>: Reduced visual acuity in one or both eyes relative to the other without an obvious defect or change in the eye</li>
<li><strong>Strabismus</strong>: Misalignment of the eyes</li>
<li><strong>Anisometropia</strong>: Difference in refractive power</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://upload.wikimedia.org/wikipedia/commons/6/6d/StrabismusVL2.jpg" alt="Wikipedia" width="900px" />

<p class="caption">

Wikipedia

</p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://www.jneurosci.org/content/jneuro/36/45/11384/F7.large.jpg" alt="[[@Kiorpes2016-ut]](https://dx.doi.org/10.1523/JNEUROSCI.2937-16.2016)" width="900px" />

<p class="caption">

<a href='https://dx.doi.org/10.1523/JNEUROSCI.2937-16.2016' title=''><span class="cite">(Kiorpes, 2016)</span></a>

</p></div>

</article></slide><slide class=""><hgroup><h2>Atypical development: Prematurity</h2></hgroup><article  id="atypical-development-prematurity">

</article></slide><slide class=""><hgroup><h2>Some (binocular functions) are experience-dependent</h2></hgroup><article  id="some-binocular-functions-are-experience-dependent">

<div class="figure" style="text-align: center">
<img src="https://www.pnas.org/content/109/27/11049/F2.medium.gif" alt="[[@Jando2012-zt]](https://dx.doi.org/10.1073/pnas.1203096109)" width="900px" />

<p class="caption">

<a href='https://dx.doi.org/10.1073/pnas.1203096109' title=''><span class="cite">(Jandó et al., 2012)</span></a>

</p></div>

</article></slide><slide class=""><hgroup><h2>Others (pattern/contrast reversal) are not</h2></hgroup><article  id="others-patterncontrast-reversal-are-not">

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="centered">

<div class="figure" style="text-align: center">
<img src="https://www.pnas.org/content/109/27/11049/F3.medium.gif" alt="[[@Jando2012-zt]](https://dx.doi.org/10.1073/pnas.1203096109)" width="900px" />

<p class="caption">

<a href='https://dx.doi.org/10.1073/pnas.1203096109' title=''><span class="cite">(Jandó et al., 2012)</span></a>

</p></div>

</article></slide><slide class=""><hgroup><h2>Atypical development: Cataract</h2></hgroup><article  class="smaller" id="atypical-development-cataract">

<div class="figure" style="text-align: center">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Cataracts_due_to_Congenital_Rubella_Syndrome_%28CRS%29_PHIL_4284_lores.jpg/600px-Cataracts_due_to_Congenital_Rubella_Syndrome_%28CRS%29_PHIL_4284_lores.jpg" alt="https://en.wikipedia.org/wiki/Congenital_cataract"  />

<p class="caption">

<a href='https://en.wikipedia.org/wiki/Congenital_cataract' title=''>https://en.wikipedia.org/wiki/Congenital_cataract</a>

</p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="https://d2ufo47lrtsv5s.cloudfront.net/content/sci/286/5437/108/F3.large.jpg?width=800&height=600&carousel=1" alt="[[@Maurer1999-yz]](https://www.ncbi.nlm.nih.gov/pubmed/10506555)" height="500px" />

<p class="caption">

<a href='https://www.ncbi.nlm.nih.gov/pubmed/10506555' title=''><span class="cite">(Maurer, Lewis, Brent, &amp; Levin, 1999)</span></a>

</p></div>

</article></slide><slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>The big picture</h2></hgroup><article  id="the-big-picture">

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="centered">
<p><img src="https://www.perkinselearning.org/sites/elearning.perkinsdev1.org/files/u2583/rectangular%20cards.jpg"></p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<blockquote>
<p>&ldquo;For me, one of the major attractions of visual science is the <strong>promise it holds for empirical attacks on the mind-body problem</strong>—that is, for working out meaningful ways to explain psychophysically defined visual functions on the basis of properties of the neural substrate.&rdquo;</p>
</blockquote>

<p>Davida Teller</p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<blockquote>
<p>&ldquo;…A critical locus or critical computation for a particular perceptual function can be defined as an anatomic or computational stage at which information concerning that function is lost or importantly reorganized…&rdquo;</p>
</blockquote>

<p>Davida Teller</p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<blockquote>
<p>&ldquo;or more poetically, as a stage or computation that leaves its mark on that perceptual capacity.&rdquo;</p>
</blockquote>

<p>Davida Teller</p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<blockquote>
<p>&ldquo;Part of the appeal of visual development is its potential for extending this promise. <strong>Visual functions mature because the visual substrate matures</strong>, and the causes of functional maturation undoubtedly lie in neural maturation.&rdquo;</p>
</blockquote>

<p>Davida Teller</p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<blockquote>
<p>&ldquo;But the length of the big toe matures too, and we do not see it as causal in relation to the development of grating acuity. The puzzle is, <strong>which of the many immaturities of the visual substrate provide the critical immaturities</strong> that limit a particular visual capacity at a particular age?&rdquo;</p>
</blockquote>

<p>Davida Teller</p>

</article></slide><slide class=""><hgroup><h2>Other things change, too…</h2></hgroup><article  id="other-things-change-too">

</article></slide><slide class=""><hgroup><h2>Simulating effects of posture change on motion</h2></hgroup><article  id="simulating-effects-of-posture-change-on-motion">

<table class = 'rmdtable'>
<tr class="header">
<th align="left">Parameter</th>
<th align="left">Crawling Infant</th>
<th align="left">Walking Infant</th>
</tr>
<tr class="odd">
<td align="left">Eye height</td>
<td align="left">0.30 m</td>
<td align="left">0.60 m</td>
</tr>
<tr class="even">
<td align="left">Locomotor speed</td>
<td align="left">0.33 m/s</td>
<td align="left">0.61 m/s</td>
</tr>
<tr class="odd">
<td align="left">Head tilt</td>
<td align="left">20 deg</td>
<td align="left">9 deg</td>
</tr>
</table>

<div class="centered">
<p></br> <img src="https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/kretch-etal.png" width=600px/> </br> <small> <a href='https://dx.doi.org/10.1111/cdev.12206' title=''>Kretch et al., 2014</a> </small></p></div>

</article></slide><slide class=""><hgroup><h2>Simulating Flow Fields</h2></hgroup><article  class="flexbox vcenter smaller" id="simulating-flow-fields">

<div class="centered">
<p><img src='https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/simulation-flow-patterns.png' width=800px/> </br> <small> <a href='https://doi.org/10.1109/DEVLRN.2015.7345450' title=''>Gilmore et al, 2015</a> </small></p></div>

</article></slide><slide class=""><hgroup><h2>Flow Direction Distributions by Geometry &amp; Posture</h2></hgroup><article  class="smaller" id="flow-direction-distributions-by-geometry-posture">

<div class="centered">
<p><img src='https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/simulation-flow-direction-hist.png' width=600px/> </br> <small> <a href='https://doi.org/10.1109/DEVLRN.2015.7345450' title=''>Gilmore et al, 2015</a> </small></p></div>

</article></slide><slide class=""><hgroup><h2>Simulated Flow Speeds (m/s)</h2></hgroup><article  class="flexbox vcenter" id="simulated-flow-speeds-ms">

<div class="centered">
<table class = 'rmdtable'>
<tr class="header">
<th align="left">Type of Locomotion</th>
<th align="left">Ground Plane</th>
<th align="left">Room</th>
<th align="left">Side Wall</th>
<th align="left">Two Walls</th>
</tr>
<tr class="odd">
<td align="left">Crawling</td>
<td align="left">14.41</td>
<td align="left">14.42</td>
<td align="left">14.43</td>
<td align="left">14.62</td>
</tr>
<tr class="even">
<td align="left">Walking</td>
<td align="left">9.38</td>
<td align="left">8.56</td>
<td align="left">7.39</td>
<td align="left">9.18</td>
</tr>
</table></div>

</article></slide><slide class=""><hgroup><h2>But, what’s the input? The <em>real</em> input?</h2></hgroup><article  id="but-whats-the-input-the-real-input">

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="centered">

<video width="750" height="450" controls>

<source src="https://nyu.databrary.org/slot/7740/0,24634/asset/16751/download?inline=true" type="video/mp4">

Your browser does not support the video tag. </video> </br> <small> (<a href='https://doi.org/10.17910/B7.116' title=''>Gilmore et al., 2015</a>) </small>

</div>

<aside class='note'><section><p>What if I had first-person, observer’s-eye views of what infants saw…</p></section></aside>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="centered">

<video data-autoplay width="750" height="450" controls>

<source src="https://nyu.databrary.org/slot/7740/0,24200/asset/16753/download?inline=true" type="video/mp4">

Your browser does not support the video tag. </video> </br> <small>(<a href='https://doi.org/10.17910/B7.116' title=''>Gilmore et al., 2015</a>)</small>

</div>

<aside class='note'><section><p>And what mothers’ saw while they moved together through the very same environment?</p></section></aside>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/mom-baby-carrier.jpg" height=350px> </br> <small> (<a href='https://doi.org/10.17910/B7.123' title=''>Adolph, 2015</a>) </small></p></div>

</article></slide><slide class=""><hgroup><h2>Frame-by-frame video analysis</h2></hgroup><article  id="frame-by-frame-video-analysis">

<div class="centered">

<video width="640" height="480" controls>

<source src="https://nyu.databrary.org/slot/11680/0,24500/asset/41871/download?inline=true" type="video/mp4">

Your browser does not support the video tag. </video> </br> <small> (<a href='https://doi.org/10.17910/B7988V' title=''>Jayaraman et al., 2015</a>) </small>

</div>

<aside class='note'><section></section></aside>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="centered">

<video width="640" height="480" controls>

<source src="https://nyu.databrary.org/slot/11680/25500,50000/asset/41873/download?inline=true" type="video/mp4">

Your browser does not support the video tag. </video>

</div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="centered">

<video width="640" height="480" controls>

<source src="https://nyu.databrary.org/slot/11680/51000,75500/asset/41875/download?inline=true" type="video/mp4">

Your browser does not support the video tag. </video>

</div>

</article></slide><slide class=""><hgroup><h2>Findings</h2></hgroup><article  class="smaller" id="findings">

<div class="centered">
<p><img src="https://raw.githubusercontent.com/gilmore-lab/temple-2017-02-27/master/img/optic-flow-locomotion.jpg" height=500px></p>

<p><small> (<a href='https://doi.org/10.1162/NECO_a_00645' title=''>Raudies &amp; Gilmore, 2014</a>) </small></p></div>

</article></slide><slide class=""><hgroup><h2>Findings</h2></hgroup><article  id="findings-1">

<ul>
<li>Infant (passengers) experience faster visual speeds than mother</li>
<li>Controlling for speed of locomotion, environment</li>
<li>Motion &ldquo;priors&rdquo; for infants ≠ mothers</li>
</ul>

</article></slide><slide class=""><hgroup><h2>Summing up…</h2></hgroup><article  id="summing-up">

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="img/atkinson-braddick-13-fig-10.1.jpg" alt="Atkinson &amp; Braddick 2010, Fig 10.1" width="434" height="550px" />

<p class="caption">

Atkinson &amp; Braddick 2010, Fig 10.1

</p></div>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<ul>
<li>Vision develops rapidly, but approaches asymptote slowly</li>
<li>Complex interplay of brain and behavioral changes</li>
</ul>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="figure" style="text-align: center">
<img src="img/atkinson-braddick-13-fig-10.4.jpg" alt="Atkinson &amp; Braddick 2010, Fig 10.4" width="700px" />

<p class="caption">

Atkinson &amp; Braddick 2010, Fig 10.4

</p></div>

</article></slide><slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>Thank you!</h2></hgroup><article  id="thank-you">

</article></slide><slide class="segue dark nobackground level1"><hgroup class = 'auto-fadein'><h2>Materials</h2></hgroup><article  id="materials">

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<p>This talk was produced on 2021-08-30 in <a href='https://rstudio.com' title=''>RStudio</a> using R Markdown. The code and materials used to generate the slides may be found at <a href='https://github.com/gilmore-lab/csd-vision-course/' title=''>https://github.com/gilmore-lab/csd-vision-course/</a>.</p>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<p>Information about the R Session that produced the code is as follows:</p>

<pre >## R version 4.1.0 (2021-05-18)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Big Sur 10.16
## 
## Matrix products: default
## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets 
## [6] methods   base     
## 
## loaded via a namespace (and not attached):
##  [1] revealjs_0.9      digest_0.6.27    
##  [3] mime_0.11         R6_2.5.0         
##  [5] jsonlite_1.7.2    magrittr_2.0.1   
##  [7] evaluate_0.14     highr_0.9        
##  [9] stringi_1.7.3     rlang_0.4.11     
## [11] jquerylib_0.1.4   bslib_0.2.5.1    
## [13] rmarkdown_2.9     tools_4.1.0      
## [15] stringr_1.4.0     jpeg_0.1-9       
## [17] xfun_0.24         yaml_2.2.1       
## [19] compiler_4.1.0    htmltools_0.5.1.1
## [21] knitr_1.33        sass_0.4.0</pre>

</article></slide><slide class=""><hgroup><h2></h2></hgroup><article >

<div class="references csl-bib-body hanging-indent" line-spacing="2" id="refs">
<div class="csl-entry" id="ref-Chan2014-il">
<p>Chan, S. C. (2014). Plenoptic function. In K. Ikeuchi (Ed.), <em>Computer vision: A reference guide</em> (pp. 618–623). Boston, MA: Springer US. <a href='https://doi.org/10.1007/978-0-387-31439-6\_7' title=''>https://doi.org/10.1007/978-0-387-31439-6\_7</a></p></div>

<div class="csl-entry" id="ref-Von_Hofsten2014-gy">
<p>Hofsten, O. von, Hofsten, C. von, Sulutvedt, U., Laeng, B., Brennen, T., &amp; Magnussen, S. (2014). Simulating newborn face perception. <em>Journal of Vision</em>, <em>14</em>(13), 16. <a href='https://doi.org/10.1167/14.13.16' title=''>https://doi.org/10.1167/14.13.16</a></p></div>

<div class="csl-entry" id="ref-Jando2012-zt">
<p>Jandó, G., Mikó-Baráth, E., Markó, K., Hollódy, K., Török, B., &amp; Kovacs, I. (2012). Early-onset binocularity in preterm infants reveals experience-dependent visual development in humans. <em>Proc. Natl. Acad. Sci. U. S. A.</em>, <em>109</em>(27), 11049–11052. <a href='https://doi.org/10.1073/pnas.1203096109' title=''>https://doi.org/10.1073/pnas.1203096109</a></p></div>

<div class="csl-entry" id="ref-Kiorpes2016-ut">
<p>Kiorpes, L. (2016). The puzzle of visual development: Behavior and neural limits. <em>J. Neurosci.</em>, <em>36</em>(45), 11384–11393. <a href='https://doi.org/10.1523/JNEUROSCI.2937-16.2016' title=''>https://doi.org/10.1523/JNEUROSCI.2937-16.2016</a></p></div>

<div class="csl-entry" id="ref-Koldewyn2010-ap">
<p>Koldewyn, K., Whitney, D., &amp; Rivera, S. M. (2010). The psychophysics of visual motion and global form processing in autism. <em>Brain: A Journal of Neurology</em>, <em>133</em>(Pt 2), 599–610. <a href='https://doi.org/10.1093/brain/awp272' title=''>https://doi.org/10.1093/brain/awp272</a></p></div>

<div class="csl-entry" id="ref-Maurer1999-yz">
<p>Maurer, D., Lewis, T. L., Brent, H. P., &amp; Levin, A. V. (1999). Rapid improvement in the acuity of infants after visual input. <em>Science</em>, <em>286</em>(5437), 108–110. Retrieved from <a href='https://www.ncbi.nlm.nih.gov/pubmed/10506555' title=''>https://www.ncbi.nlm.nih.gov/pubmed/10506555</a></p></div>

<div class="csl-entry" id="ref-Mirabella2006-ro">
<p>Mirabella, G., Kjaer, P. K., Norcia, A. M., Good, W. V., &amp; Madan, A. (2006). Visual development in very low birth weight infants. <em>Pediatr. Res.</em>, <em>60</em>(4), 435–439. <a href='https://doi.org/10.1203/01.pdr.0000238249.44088.2c' title=''>https://doi.org/10.1203/01.pdr.0000238249.44088.2c</a></p></div>

<div class="csl-entry" id="ref-Tootell2003-oo">
<p>Tootell, R. B. H., Tsao, D., &amp; Vanduffel, W. (2003). Neuroimaging weighs in: Humans meet macaques in <span>
“primate”</span> visual cortex. <em>The Journal of Neuroscience: The Official Journal of the Society for Neuroscience</em>, <em>23</em>(10), 3981–3989. <a href='https://doi.org/10.1523/JNEUROSCI.23-10-03981.2003' title=''>https://doi.org/10.1523/JNEUROSCI.23-10-03981.2003</a></p></div></div></article></slide>


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
